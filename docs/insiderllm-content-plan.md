# InsiderLLM Master Content Plan

## Overview
- **Goal:** 100 articles
- **Current:** 57 articles (as of Feb 4, 2026)
- **Focus:** Budget-friendly local AI for hobbyists and developers
- **Brand voice:** Practical, honest, no fluff

---

## âœ… PUBLISHED (20 articles)

1. GPU Buying Guide for Local AI
2. RTX 5060 Ti 16GB News
3. VRAM Requirements Guide
4. Used RTX 3090 Buying Guide
5. NVIDIA Price Hikes Analysis
6. Ollama vs LM Studio
7. Run Your First Local LLM
8. Budget AI PC Under $500
9. Quantization Explained
10. AMD vs NVIDIA for Local AI
11. What Can You Run on 8GB VRAM
12. What Can You Run on 12GB VRAM
13. What Can You Run on 16GB VRAM
14. What Can You Run on 24GB VRAM
15. Best Models for Coding Locally
16. CPU-Only LLMs: What Actually Works
17. Stable Diffusion Locally: Getting Started
18. Best Models Under 3B Parameters
19. Mac vs PC for Local AI
20. Context Length Explained
21. Local RAG: Search Your Documents with a Private AI
22. What Can You Actually Run on 4GB VRAM?
23. Model Formats Explained: GGUF vs GPTQ vs AWQ vs EXL2
24. Used GPU Buying Guide for Local AI: How to Buy Smart
25. Best Local LLMs for Writing & Creative Work
26. Local LLMs vs ChatGPT: Honest Comparison
27. Ollama Troubleshooting Guide
28. Best Local LLMs for Chat & Conversation
29. Flux Locally: Complete Guide
30. Laptop vs Desktop for Local AI
31. LM Studio Tips & Tricks
32. Voice Chat with Local LLMs: Whisper + TTS
33. Open WebUI Setup Guide
34. DeepSeek Models Guide: R1, V3, and Coder
35. ComfyUI vs Automatic1111 vs Fooocus
36. Llama 3 Guide: Every Size from 1B to 405B
37. OpenClaw Security Guide: What You Need to Know Before Running It
38. OpenClaw Setup Guide: Run a Local AI Agent on Your Own Hardware
39. Qwen Models Guide: The Best Open-Source AI Family You're Not Using
40. Best Local LLMs for Math & Reasoning: What Actually Works
41. llama.cpp vs Ollama vs vLLM: When to Use Each
42. Mistral & Mixtral Guide: Every Model Worth Running Locally
43. Local LLMs vs Claude: When Each Actually Wins
44. Fine-Tuning LLMs on Consumer Hardware: LoRA and QLoRA Guide
45. Text Generation WebUI (Oobabooga) Guide: The Power User's Local AI Interface
46. Best Local Models for OpenClaw: What to Run for AI Agent Tasks
47. OpenClaw vs Commercial AI Agents: Which Should You Use?
48. Local AI Troubleshooting Guide
49. Running LLMs on Mac M-Series
50. Best GPU Under $300 for Local AI
51. RTX 3090 vs RTX 4070 Ti Super for Local LLMs
52. Best GPU Under $500 for Local AI
53. Best Used GPUs for Local AI 2026
54. How Much Does It Cost to Run LLMs Locally
55. OpenClaw Token Optimization
56. Tiered AI Model Strategy / Stop Using Frontier AI for Everything

---

## ðŸŽ¯ CATEGORY 1: Hardware & VRAM (Target: 25 articles)
*Your core expertise â€” budget hardware decisions*

### Published (21)
- [x] GPU Buying Guide for Local AI
- [x] RTX 5060 Ti 16GB News
- [x] VRAM Requirements Guide
- [x] Used RTX 3090 Buying Guide
- [x] NVIDIA Price Hikes Analysis
- [x] AMD vs NVIDIA for Local AI
- [x] Budget AI PC Under $500
- [x] What Can You Run on 8GB VRAM
- [x] What Can You Run on 12GB VRAM
- [x] What Can You Run on 16GB VRAM
- [x] What Can You Run on 24GB VRAM
- [x] What Can You Run on 4GB VRAM
- [x] CPU-Only LLMs
- [x] Mac vs PC for Local AI
- [x] Best Models Under 3B Parameters
- [x] Running LLMs on Mac M-Series
- [x] Best GPU Under $300 for Local AI
- [x] RTX 3090 vs RTX 4070 Ti Super for Local LLMs
- [x] Best GPU Under $500 for Local AI
- [x] Best Used GPUs for Local AI 2026
- [x] Laptop vs Desktop for Local AI

### Priority 1 (Next 10 to hit 30)
- [ ] RTX 3060 vs 3060 Ti vs 3070 for Local AI â€” common upgrade decisions
- [ ] Power Supply Guide for AI Builds â€” 3090 needs 850W, etc.
- [ ] Cooling Solutions for GPU-Heavy Builds â€” thermals matter
- [ ] Multi-GPU Setups: Worth It? â€” NVLink, tensor parallelism, reality check
- [ ] Intel Arc for Local AI â€” A770/A750, underdog option
- [ ] RAM Speed and Local AI â€” DDR4 vs DDR5, channel config
- [ ] SSD vs HDD for Model Storage â€” load times, practical difference

### Priority 2 (Backlog)
- [ ] Used Tesla P40 for Local AI â€” datacenter card budget option
- [ ] RTX 4090 vs Used 3090: Which to Buy
- [ ] Workstation vs Gaming GPU for AI
- [ ] eGPU for Local AI â€” Thunderbolt setups
- [ ] Building a Dedicated AI Server
- [ ] Noise and Heat Management for AI Rigs
- [ ] Buying Refurbished GPUs Safely

---

## ðŸŽ¯ CATEGORY 2: Software & Tools (Target: 20 articles)
*Setup guides, comparisons, troubleshooting*

### Published (13)
- [x] Ollama vs LM Studio
- [x] Run Your First Local LLM
- [x] Quantization Explained
- [x] Context Length Explained
- [x] Model Formats Explained â€” GGUF, GPTQ, AWQ, EXL2
- [x] LM Studio Tips & Tricks
- [x] Ollama Troubleshooting Guide
- [x] llama.cpp vs Ollama vs vLLM
- [x] Open WebUI Setup Guide
- [x] Text Generation WebUI (Oobabooga) Guide
- [x] Local AI Troubleshooting Guide
- [x] OpenClaw Token Optimization

### Priority 1
- [x] Ollama Troubleshooting Guide â€” common errors, fixes
- [x] LM Studio Tips & Tricks â€” hidden features, optimization
- [x] llama.cpp vs Ollama vs vLLM â€” when to use each
- [x] Open WebUI Setup Guide â€” ChatGPT-like interface
- [x] Text Generation WebUI (Oobabooga) Guide
- [ ] AnythingLLM Setup Guide â€” RAG made easy
- [ ] LocalAI Setup Guide â€” OpenAI-compatible API
- [ ] How to Update Models in Ollama
- [ ] Managing Multiple Models â€” disk space, switching

### Priority 2
- [ ] TabbyML for Local Code Completion
- [ ] Continue Extension Setup (VSCode)
- [ ] Aider for AI Pair Programming
- [ ] Setting Up a Local API Server
- [ ] Docker for Local AI â€” containerized setups
- [ ] WSL2 for Local AI on Windows
- [ ] Benchmarking Your Local Setup â€” how to measure tok/s

---

## ðŸŽ¯ CATEGORY 3: Models & Use Cases (Target: 25 articles)
*Which model for which task*

### Published (3)
- [x] Best Models for Coding Locally
- [x] Stable Diffusion Locally
- [x] Best Models for Writing & Creative Work

### Priority 1
- [x] Best Models for Chat & Conversation
- [ ] Best Models for Summarization
- [ ] Best Models for Translation
- [ ] Best Models for Data Analysis
- [x] Best Models for Math & Reasoning
- [ ] Best Uncensored Models (and why you might want them)
- [x] Qwen 2.5 Complete Guide â€” all sizes, use cases
- [x] Llama 3.1/3.2/3.3 Complete Guide
- [x] Mistral & Mixtral Guide
- [x] DeepSeek Models Guide â€” R1, Coder, etc.

### Priority 2
- [ ] Phi Models Guide (Microsoft)
- [ ] Gemma Models Guide (Google)
- [ ] CodeLlama vs DeepSeek Coder vs Qwen Coder
- [ ] Best Models for Roleplay & Fiction
- [ ] Best Models for Research & Analysis
- [ ] Best Models for Customer Support Bots
- [ ] Best Models for Email Writing
- [ ] MoE Models Explained â€” Mixtral, DBRX, etc.
- [ ] Vision Models Locally â€” LLaVA, Qwen-VL
- [ ] Embedding Models for RAG
- [ ] Best Models by Language (non-English)
- [ ] Fine-Tuned vs Base Models â€” when to use each
- [ ] Censorship in Local Models â€” what's filtered, workarounds

---

## ðŸŽ¯ CATEGORY 4: Image & Creative AI (Target: 12 articles)
*Stable Diffusion, Flux, creative tools*

### Published (2)
- [x] Stable Diffusion Locally: Getting Started
- [x] Flux Locally: Complete Guide

### Priority 1
- [x] ComfyUI vs Automatic1111 vs Fooocus
- [ ] Best Checkpoints for Photorealism
- [ ] Best Checkpoints for Anime/Illustration
- [ ] LoRA Training on Consumer Hardware
- [ ] ControlNet Guide for Beginners
- [ ] Inpainting and Outpainting Guide

### Priority 2
- [ ] SDXL vs SD 1.5 vs Flux â€” which to use
- [ ] Upscaling with AI Locally
- [ ] AI Video Generation Locally â€” SVD, AnimateDiff
- [ ] Running DALL-E Alternatives Locally
- [ ] Prompt Engineering for Image Gen

---

## ðŸŽ¯ CATEGORY 5: Advanced Topics (Target: 10 articles)
*For users ready to go deeper*

### Published (6)
- [x] RAG Basics for Local LLMs
- [x] Voice Chat with Local LLMs â€” Whisper + TTS
- [x] Fine-Tuning on Consumer Hardware â€” LoRA, QLoRA
- [x] OpenClaw Security Guide
- [x] OpenClaw Setup Guide
- [x] Tiered AI Model Strategy / Stop Using Frontier AI for Everything

### Priority 1
- [ ] Building a Local AI Assistant
- [ ] Local AI for Privacy: What's Actually Private

### Priority 2
- [ ] Function Calling with Local Models
- [x] OpenClaw Security Guide â€” AI agent risks and hardening
- [x] OpenClaw Setup Guide â€” installation, messaging, Ollama, Cloudflare
- [ ] Agents with Local LLMs â€” AutoGPT-style
- [ ] Structured Output from Local Models
- [ ] Speculative Decoding Explained
- [ ] KV Cache Optimization Deep Dive

---

## ðŸŽ¯ CATEGORY 6: Comparisons & Alternatives (Target: 8 articles)
*Local vs cloud, tool comparisons*

**Note:** Comparison articles ("X vs Y") are top GSC performers â€” prioritize these.

### Published (4)
- [x] Local LLMs vs ChatGPT: Honest Comparison
- [x] Local LLMs vs Claude: When Each Wins
- [x] OpenClaw vs Commercial AI Agents
- [x] How Much Does It Cost to Run LLMs Locally

### Priority 1
- [ ] Ollama vs LM Studio vs LocalAI â€” three-way tool comparison
- [ ] Qwen vs Llama vs Mistral â€” model family shootout
- [ ] RTX 3060 vs 3070 vs 3080 for Local AI â€” mid-range GPU comparison
- [ ] Free Local AI vs Paid Cloud APIs â€” cost analysis
- [ ] Running AI Offline: Complete Guide

### Priority 2
- [ ] Anthropic vs OpenAI vs Local â€” decision framework
- [ ] When to Use Cloud vs Local
- [ ] Privacy: Local vs Cloud AI
- [ ] Cost Calculator: Local vs API

---

## ðŸ“Š CONTENT CALENDAR

### Week 1 (Jan 26-31): Foundation âœ…
- Target: 30 articles
- Status: 30 done âœ…
- Focus: Hardware, VRAM guides, getting started

### Week 2 (Feb 1-7): Expansion âœ…
- Target: 45 articles (+15)
- Status: 57 done âœ… (exceeded by 12)
- Focus: Software tools, model guides, troubleshooting

### Week 3 (Feb 8-14): Depth
- Target: 60 articles (+15)
- Focus: Use cases, comparisons, image gen

### Week 4 (Feb 15-21): Advanced
- Target: 75 articles (+15)
- Focus: RAG, fine-tuning, advanced topics

### Month 2: Complete
- Target: 100 articles
- Focus: Fill gaps, update older articles, SEO optimization

---

## ðŸ”¥ QUICK WINS (Easy to write, high value)

These can be knocked out fast with CC:

1. ~~Best Models for Writing & Creative Work~~ âœ…
~~Ollama Troubleshooting Guide~~ âœ…
3. ~~What Can You Run on 4GB VRAM~~ âœ…
4. ~~Used GPU Buying Guide (General)~~ âœ…
~~Best Models for Chat & Conversation~~ âœ…
~~LM Studio Tips & Tricks~~ âœ…
~~Flux Locally: Complete Guide~~ âœ…
8. ~~RAG Basics for Local LLMs~~ âœ…
~~Local LLMs vs ChatGPT: Honest Comparison~~ âœ…
~~Voice Chat with Local LLMs~~ âœ…

---

## ðŸ“ˆ SEO PRIORITY (High search volume)

Based on typical search patterns:

1. "best GPU for local LLM" âœ… done
2. "ollama vs lm studio" âœ… done
3. "how to run llama locally" âœ… done
4. "stable diffusion locally" âœ… done
5. "best local LLM for coding" âœ… done
6. "how much VRAM for LLM" âœ… done
7. "RTX 3090 for AI" âœ… done
8. "Mac vs PC for AI" âœ… done
9. "best small LLM" âœ… done
10. "local LLM vs ChatGPT" âœ… done
11. "flux locally" âœ… done
12. "RAG local LLM" âœ… done
13. "fine tune LLM locally" âœ… done
14. "whisper local" âœ… done
15. "comfyui vs automatic1111" âœ… done

---

## Notes

- **Brand focus:** Budget-conscious, practical, honest
- **Avoid:** Enterprise, cloud-first, overly technical without practical application
- **Tone:** "I figured this out so you don't have to"
- **Internal linking:** Every article links to 3-5 related guides
- **Update cadence:** Refresh hardware articles quarterly (prices change)

---

## ðŸŽ¯ BATCH 2: Articles #110-169 (60 articles)

*Expansion beyond core guides â€” new verticals, deeper technical content, troubleshooting, and distributed AI.*

---

### CATEGORY 7: Architecture & Future Tech (5 articles)
*What comes after transformers â€” and what you can run today*

- [ ] #110: Beyond Transformers: 5 Architectures for Your $50 Mini PC (RWKV-7, Mamba, SSMs, xLSTM, Hyena)
- [ ] #111: What Is Mamba and Why Should You Care?
- [ ] #112: RWKV Explained: Infinite Context on Consumer Hardware
- [ ] #113: State Space Models vs Transformers: When to Use Each
- [ ] #114: The Post-Attention Era: What Comes After Transformers

### CATEGORY 8: Phone/Mobile AI (5 articles)
*Running AI on devices you already own*

- [ ] #115: Running AI on an Old Android Phone
- [ ] #116: Your Old Phone as a mycoSwarm Node
- [ ] #117: Termux + Ollama: Local LLM on Android
- [ ] #118: Phone vs Raspberry Pi: Which Edge Device Wins?
- [ ] #119: Building a $0 AI Node From E-Waste Phones

### CATEGORY 9: Troubleshooting (10 articles)
*Fix the specific errors people actually search for*

- [x] #120: Ollama Not Using GPU: Complete Fix Guide (/guides/ollama-not-using-gpu-fix/)
- [x] #121: CUDA Out of Memory: What It Means and How to Fix It (/guides/cuda-out-of-memory-fix/)
- [x] #122: Why Is My Local LLM So Slow? (/guides/why-local-llm-slow/)
- [x] #123: llama.cpp Build Errors: Common Fixes (/guides/llamacpp-build-errors-fixes/)
- [x] #124: Model Outputs Garbage: Debugging Bad Generations (/guides/model-outputs-garbage-debug/)
- [x] #125: ROCm Not Detecting GPU: AMD Troubleshooting (/guides/rocm-not-detecting-gpu-amd-fix/)
- [x] #126: Ollama API Connection Refused: Quick Fixes (/guides/ollama-api-connection-refused-fix/)
- [x] #127: GGUF File Won't Load: Format and Compatibility Issues (/guides/gguf-file-wont-load-fix/)
- [x] #128: Context Length Exceeded: What To Do (/guides/context-length-exceeded-fix/)
- [x] #129: Memory Leak in Long Conversations: Causes and Fixes (/guides/memory-leak-long-conversations-fix/)

### CATEGORY 10: Industry Verticals (8 articles)
*Local AI for specific professions â€” privacy and practical use cases*

- [ ] #130: Local AI for Lawyers: Confidential Document Analysis
- [ ] #131: Local AI for Therapists: Session Notes Without Cloud Risk
- [ ] #132: Local AI for Accountants: Tax Prep and Financial Analysis
- [ ] #133: Local AI for Writers: Fiction, Editing, and Research
- [ ] #134: Local AI for Developers: Beyond Copilot
- [ ] #135: Local AI for Researchers: Literature Review and Synthesis
- [ ] #136: Local AI for Teachers: Grading and Curriculum
- [ ] #137: Local AI for Small Business: Automation Without Subscriptions

### CATEGORY 11: Model Deep Dives (7 articles)
*Complete guides for model families not yet covered*

- [x] #138: Qwen3 Complete Guide: Every Model from 0.6B to 235B (/guides/qwen3-complete-guide/)
- [ ] #139: Complete Guide to Llama 3: When to Use Each Variant
- [ ] #140: Complete Guide to Phi-3/Phi-4: Microsoft's Small Models
- [ ] #141: Complete Guide to Gemma 2: Google's Local Option
- [ ] #142: Complete Guide to Command-R: Cohere's RAG Model
- [ ] #143: Yi Models Explained: The Underrated Chinese Option
- [ ] #144: Solar, EXAONE, and Other Models You've Never Heard Of
- [x] #144b: Llama 4 Guide: Running Scout and Maverick Locally (/guides/llama-4-guide-scout-maverick/)
- [x] #144c: DeepSeek V3.2 Guide: What Changed and How to Run It Locally (/guides/deepseek-v3-2-guide/)
- [x] #144d: Llama 4 vs Qwen3 vs DeepSeek V3.2: Which to Run Locally in 2026 (/guides/llama-4-vs-qwen3-vs-deepseek-v3-2-local/)
- [x] #144e: GPT-OSS Guide: OpenAI's First Open Model for Local AI (/guides/gpt-oss-guide-openai-local/)
- [x] #144f: OpenClaw's Creator Just Joined OpenAI â€” What It Means for Local AI Agents (/guides/openclaw-openai-acquihire-what-it-means/)
- [x] #144g: Mixtral VRAM Requirements: 8x7B and 8x22B at Every Quantization Level (/guides/mixtral-vram-requirements/)
- [x] #144h: Mac Mini M4 for Local AI: Which Config to Buy (/guides/mac-mini-m4-local-ai/)

### CATEGORY 12: Hardware Updates (5 articles)
*Current-gen hardware reviews and comparisons*

- [ ] #145: RTX 5090 for Local AI: Worth the Upgrade?
- [ ] #146: M4 Max/Ultra for LLMs: Apple Silicon Ceiling
- [ ] #147: Intel Arc B-Series: Budget AI Finally Works?
- [ ] #148: Used Server GPUs: Tesla P40, A100 on eBay
- [ ] #149: Mini PC Roundup 2026: Best for Local AI Under $300

### CATEGORY 13: Workflow/Integration (5 articles)
*Connecting local AI to the tools you already use*

- [ ] #150: Obsidian + Local LLM: Your Second Brain
- [ ] #151: VS Code + Local Models: Copilot Alternative
- [ ] #152: Local AI + Home Assistant: Smart Home Automation
- [ ] #153: Local AI + Notion: Private Workspace Intelligence
- [ ] #154: Voice Control for Local AI: Whisper + TTS Pipeline

### CATEGORY 14: mycoSwarm/Distributed (5 articles)
*Multi-node AI architecture and distributed inference*

- [x] #155: Distributed Wisdom: Running a Thinking Network on $200 Hardware (/guides/distributed-wisdom-thinking-network/)
- [ ] #156: Cross-Network Inference: How mycoSwarm Routes Queries
- [x] #157: Why Your AI Keeps Lying: The Hallucination Feedback Loop (/guides/hallucination-feedback-loop/)
- [ ] #158: Intent Classification on Tiny Models
- [ ] #159: The Coordinator Pattern: Pi as Brain, GPUs as Muscle
- [x] #159b: What Happens When You Give a Local AI an Identity (And Then Ask It About Love) (/guides/teaching-ai-what-love-means/)
- [x] #159c: We Asked Our Local AI What Happens When We Turn Off the Computer (/guides/teaching-ai-about-death-ship-of-theseus/)

### CATEGORY 15: AI Design Problems (10 articles)
*Hard problems in applied AI â€” solutions that work locally*

- [ ] #160: What Is Context Rot and How to Fix It
- [ ] #161: Poisoned Memories: When RAG Goes Wrong
- [ ] #162: Hallucination Detection: Patterns That Work
- [ ] #163: Prompt Injection Defense for Local Systems
- [ ] #164: Chunking Strategies: Why 512 Tokens Isn't Always Right
- [ ] #165: The Embedding Model Matters More Than You Think
- [ ] #166: Retrieval vs Generation: When RAG Hurts More Than Helps
- [ ] #167: Session Continuity Without Infinite Context
- [ ] #168: Graceful Degradation: What To Do When the GPU Is Busy
- [ ] #169: Evaluating AI Outputs When You Don't Have Ground Truth
